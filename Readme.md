# SystÃ¨me de Suivi de Commandes Kafka (Kafka Order Tracking System)

Bienvenue dans le projet de dÃ©monstration **Kafka Order Tracking**. Ce projet est une implÃ©mentation de rÃ©fÃ©rence en **Go** illustrant une architecture Ã©vÃ©nementielle (EDA) robuste utilisant **Apache Kafka**. Il simule un flux de commandes e-commerce complet, de la production Ã  la consommation, avec une observabilitÃ© avancÃ©e.

## ðŸ“‹ Table des MatiÃ¨res

- [FonctionnalitÃ©s et Patterns](#-fonctionnalitÃ©s-et-patterns)
- [PrÃ©requis](#-prÃ©requis)
- [DÃ©marrage Rapide](#-dÃ©marrage-rapide)
- [Utilisation et Monitoring](#-utilisation-et-monitoring)
- [ArrÃªt du SystÃ¨me](#-arrÃªt-du-systÃ¨me)
- [Configuration](#-configuration)
- [Structure du Projet](#-structure-du-projet)
- [DÃ©veloppement et Tests](#-dÃ©veloppement-et-tests)

---

## ðŸŒŸ FonctionnalitÃ©s et Patterns

Ce projet met en Å“uvre les meilleures pratiques de l'ingÃ©nierie logicielle distribuÃ©e :

- **Event-Driven Architecture (EDA)** : DÃ©couplage total entre le producteur et le consommateur.
- **Event Carried State Transfer (ECST)** : Les messages contiennent tout le contexte nÃ©cessaire.
- **Retry Pattern** : Backoff exponentiel avec jitter pour gÃ©rer les erreurs transitoires.
- **Dead Letter Queue (DLQ)** : Messages en Ã©chec envoyÃ©s vers `orders-dlq` pour analyse.
- **Graceful Shutdown** : Gestion propre des signaux (SIGTERM, SIGINT).
- **Configuration Externe** : Fichier YAML + variables d'environnement.

---

## ðŸ›  PrÃ©requis

Avant de commencer, assurez-vous d'avoir installÃ© :

1.  **Docker** et **Docker Compose** (V2).
2.  **Go** (version 1.22 ou supÃ©rieure).
3.  **GCC/MinGW** (ou Docker pour la compilation) - requis pour `confluent-kafka-go`.
4.  Un terminal compatible ANSI (pour le moniteur).
5.  PrivilÃ¨ges `sudo` (requis pour les commandes Docker dans les scripts).

---

## ðŸš€ DÃ©marrage Rapide

### MÃ©thode 1 : Script AutomatisÃ© (RecommandÃ©)

Le projet fournit des scripts pour gÃ©rer le cycle de vie complet :

```bash
# 1. DÃ©marrer l'environnement complet
./start.sh
```

**Ce que fait `start.sh` :**

1. âœ… DÃ©marre le conteneur Kafka via Docker Compose
2. âœ… Attend que Kafka soit prÃªt (attente active)
3. âœ… CrÃ©e le topic `orders` automatiquement
4. âœ… Compile les binaires dans `bin/`
5. âœ… Lance le **Tracker** (consommateur) en arriÃ¨re-plan
6. âœ… Lance le **Producer** (producteur) en arriÃ¨re-plan

```bash
# 2. ArrÃªter proprement l'environnement
./stop.sh
```

**Ce que fait `stop.sh` :**

1. âœ… Envoie SIGTERM au producer (arrÃªt gracieux)
2. âœ… Envoie SIGTERM au tracker (traite les messages restants)
3. âœ… Attend la fin des processus (timeout 15s)
4. âœ… ArrÃªt forcÃ© si nÃ©cessaire (SIGKILL)
5. âœ… ArrÃªte les conteneurs Docker

### MÃ©thode 2 : Lancement Manuel

Si vous prÃ©fÃ©rez un contrÃ´le plus fin :

```bash
# Terminal 1 : DÃ©marrer Kafka
docker compose up -d

# Attendre que Kafka soit prÃªt, puis crÃ©er le topic
docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic orders --partitions 1 --replication-factor 1

# Terminal 2 : Compiler et lancer le tracker
go build -tags kafka -o bin/tracker ./cmd/tracker
./bin/tracker

# Terminal 3 : Compiler et lancer le producer
go build -tags kafka -o bin/producer ./cmd/producer
./bin/producer

# Terminal 4 : Lancer le moniteur
go build -o bin/monitor ./cmd/monitor
./bin/monitor
```

---

## ðŸ“Š Utilisation et Monitoring

Une fois le systÃ¨me lancÃ©, plusieurs mÃ©thodes s'offrent Ã  vous pour observer l'activitÃ©.

### 1. Le Moniteur Interactif (RecommandÃ©)

Lancez le moniteur dans un **nouveau terminal** :

```bash
./bin/monitor
```

- **Touches** : `q` ou `Ctrl+C` pour quitter.
- **FonctionnalitÃ©s** : Affiche le dÃ©bit (msg/sec), le taux de succÃ¨s, et les derniers logs.

### 2. Observation des Logs Bruts

```bash
# ActivitÃ© mÃ©tier (Audit)
tail -f tracker.events

# SantÃ© technique (Logs JSON)
tail -f tracker.log | jq
```

---

## ðŸ›‘ ArrÃªt du SystÃ¨me

```bash
./stop.sh
```

Ce script :

- Utilise les fichiers PID (`producer.pid`, `tracker.pid`) pour identifier les processus
- Envoie SIGTERM pour un arrÃªt gracieux
- Laisse le temps aux applications de terminer (flush des messages)
- ArrÃªte l'infrastructure Docker

---

## âš™ï¸ Configuration

### Fichier de Configuration

Copiez le template et personnalisez :

```bash
cp config.yaml.example config.yaml
```

Options principales :

```yaml
kafka:
  broker: "localhost:9092" # Adresse du broker
  topic: "orders" # Topic Kafka
  consumer_group: "order-tracker-group"

producer:
  interval_ms: 2000 # Intervalle entre messages

retry:
  max_attempts: 3 # Tentatives max avant DLQ
  initial_delay_ms: 100 # DÃ©lai initial
  multiplier: 2.0 # Multiplicateur backoff

dlq:
  enabled: true # Activer Dead Letter Queue
  topic: "orders-dlq"
```

### Variables d'Environnement

Les variables d'environnement surchargent le fichier YAML :

| Variable               | Description               |
| ---------------------- | ------------------------- |
| `KAFKA_BROKER`         | Adresse du broker Kafka   |
| `KAFKA_TOPIC`          | Nom du topic              |
| `PRODUCER_INTERVAL_MS` | Intervalle entre messages |
| `RETRY_MAX_ATTEMPTS`   | Nombre max de tentatives  |
| `DLQ_ENABLED`          | Activer/dÃ©sactiver DLQ    |

---

## ðŸ“‚ Structure du Projet

```
PubSub/
â”œâ”€â”€ cmd/                           # Points d'entrÃ©e
â”‚   â”œâ”€â”€ producer/main.go
â”‚   â”œâ”€â”€ tracker/main.go
â”‚   â””â”€â”€ monitor/main.go
â”œâ”€â”€ internal/                      # Paquets privÃ©s
â”‚   â”œâ”€â”€ config/                   # Configuration
â”‚   â”‚   â”œâ”€â”€ config.go            # Constantes
â”‚   â”‚   â””â”€â”€ loader.go            # Chargeur YAML/env
â”‚   â”œâ”€â”€ producer/                 # Logique producteur
â”‚   â”œâ”€â”€ tracker/                  # Logique consommateur
â”‚   â”œâ”€â”€ monitor/                  # Logique TUI
â”‚   â””â”€â”€ retry/                    # Retry + DLQ
â”‚       â”œâ”€â”€ retry.go             # Backoff exponentiel
â”‚       â””â”€â”€ dlq.go               # Dead Letter Queue
â”œâ”€â”€ pkg/models/                    # ModÃ¨les partagÃ©s
â”‚   â”œâ”€â”€ order.go
â”‚   â””â”€â”€ logging.go
â”œâ”€â”€ bin/                           # Binaires (gÃ©nÃ©rÃ©)
â”œâ”€â”€ start.sh                       # DÃ©marrage automatisÃ©
â”œâ”€â”€ stop.sh                        # ArrÃªt gracieux
â”œâ”€â”€ config.yaml.example            # Template configuration
â””â”€â”€ docker-compose.yaml            # Kafka Docker
```

---

## ðŸ’» DÃ©veloppement et Tests

### Compilation

```bash
# Tous les binaires
make build

# Individuellement
make build-producer   # bin/producer
make build-tracker    # bin/tracker
make build-monitor    # bin/monitor
```

### Tests

```bash
# Tous les tests
make test

# Tests par package
go test -v ./pkg/models/...      # ModÃ¨les
go test -v ./internal/retry/...  # Retry pattern
go test -tags kafka -v ./internal/producer/...  # Producer
```

> **Note CGO** : Les packages `producer` et `tracker` utilisent `confluent-kafka-go` qui nÃ©cessite CGO. Pour compiler sur Windows sans GCC, utilisez Docker :
>
> ```bash
> docker run --rm -v $(pwd):/app -w /app golang:1.22 make build
> ```
